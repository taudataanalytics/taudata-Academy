{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img alt=\"\" src=\"images/Cover_UnMuh_2021.png\"/></center> \n",
    "\n",
    "# <center><font color=\"black\">Implementasi Deep Learning Bagian ke-01 <br> http://bit.ly/unmuh-A-2021</font></center>\n",
    "## <center><font color=\"black\">(C) Taufik Sutanto - 2021 <br> tau-data Indonesia ~ https://tau-data.id/</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color=\"blue\">Outline Module Implementasi A :</font>\n",
    "\n",
    "* getting ready with Deep Learning & GPU\n",
    "* Deep learning for Binary Classification\n",
    "* Deep Learning for Multi-Classification\n",
    "* Deep Learning for Regression\n",
    "* Deep Learning for Clustering\n",
    "* Hyperparameter Optimization & Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalasi Lokal GPU Support (TensorFlow-CUDA) untuk model Deep Learning. \n",
    "\n",
    "* Link ini akan membantu menyesuaikan versi CUDA dan CudNN yang tepat untuk semua versi TensorFlow.  Hati-hati!!!.... requirement CUDA dan CudNN berbeda antara Linux & Windows (Walau versi tensorflow-nya sama!!!).\n",
    "* Berikut Versi Keras-TensorFlow yang bersesuaiannya: https://docs.floydhub.com/guides/environments/\n",
    "Download Cuda dan CudNN yang bersesuaian (seringnya BUKAN versi terakhir) dari sini (need to register):\n",
    "* https://developer.nvidia.com/cuda-downloads\n",
    "* https://developer.nvidia.com/rdp/cudnn-archive\n",
    " - Copy all files ke instalasi path cuda computing toolkit\n",
    " - https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html \n",
    "* Restart\n",
    "\n",
    "* Setelah install Cuda/Cudnn, jika compiler terinstall dengan baik, maka perintah **pip install --upgrade tensorflow-gpu** bisa digunakan di terminal/command prompt.\n",
    "\n",
    "[Linux]:  https://www.tensorflow.org/install/source#tested_build_configurations \n",
    "\n",
    "[Windows]:  https://www.tensorflow.org/install/source_windows \n",
    "\n",
    "Untuk \"PyTorch\" cenderung lebih mudah: https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning di Google Colaboratory (Recommended*)\n",
    "\n",
    "* Free with GPU (& TPU) support (Max run ~ 10jam)\n",
    "* Login dengan Username dan password Google\n",
    "* Kunjungi https://colab.research.google.com\n",
    "* New Python 3 Notebook, rename/save Notebook \n",
    "\n",
    "## Runtime>Change runtime type and select GPU as Hardware accelerator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingat di Google Colab/Jupyter Notebook Urutan eksekusi Cell Penting\n",
    "\n",
    "### Jangan ada yang terlewat.\n",
    "### Untuk Memudahkan yakinkan \"side-by-side\" antara Zoom dan Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing some supporting libraries\n",
    "import pickle, numpy as np, warnings; warnings.simplefilter('ignore')\n",
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version = \", tf.__version__)\n",
    "if tf.test.is_built_with_cuda():\n",
    "    physical_devices = tf.config.list_physical_devices('GPU') \n",
    "    print(\"CUDA enabled TF, Num GPUs:\", len(physical_devices), physical_devices) \n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Sentiment Analysis\n",
    "\n",
    "<img alt=\"\" src=\"images/movies.jpg \"/>\n",
    "\n",
    "* Di contoh pertama kita akan menggunakan data IMDB.\n",
    "* Data ini relatif \"mudah\" dan cocok untuk pemula.\n",
    "* Data berupa Text, namun dapat langsung diakses bentuk labeled-nya\n",
    "* Terdiri dari review **Sentimen** positif dan negatif dari film-film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "try:\n",
    "    f = open('data/imdb.pckl', 'rb') # Menghindari downloading data berkali-kali\n",
    "    (train_data, train_labels), (test_data, test_labels) = pickle.load(f); f.close()\n",
    "except:\n",
    "    (train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "    # num_words=10000 artinya 10,000 kata yang sering muncul. \n",
    "    f = open('data/imdb.pckl', 'wb') # save ke lokal drive\n",
    "    pickle.dump(((train_data, train_labels), (test_data, test_labels)), f); f.close()\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips\n",
    "\n",
    "### Di Data Science, Machine Learning, & AI selalu perhatikan struktur data input dan output dengan baik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_data), train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagaimana memahami struktur data ini?\n",
    "train_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coba duga makna angka-angka ini\n",
    "type(train_data[0]), len(train_data[0]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index is a dictionary mapping words to an integer index\n",
    "word_index = imdb.get_word_index()\n",
    "# We reverse it, mapping integer indices to words\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# We decode the review; note that our indices were offset by 3\n",
    "# because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n",
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Struktur Data, Struktur Data, Struktur Data\n",
    "\n",
    "* ANN/DL via DL tidak dapat menerima input (domain) list dari integer.\n",
    "* Input data harus diubah terlebih dahulu menjadi **Tensor**\n",
    "* Lakukan \"Pad\" agar semua memiliki panjang yang sama.\n",
    "* Kemudian Rubah ke Tensor\n",
    "* Gunakan Embedding layer (word2Vec) untuk mendapatkan tensor dari dokumen yang akan dioptimasi untuk klasifikasi.\n",
    "* Struktur Data input cocok/siap untuk digunakan pada layer/network DL.\n",
    "\n",
    "### Masih belum jelas? Mari kita bahas perlahan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setiap kata akan masuk ke network kita\n",
    "\n",
    "* Bayangkan setiap kata sebagai variabel/feature/indicator sebagaimana Vector Space Model\n",
    "\n",
    "<ul>\n",
    "\t<li>Misal kita kembali menggunakan penjelasan kata per kata yang masuk ke network kita</li>\n",
    "\t<li><img alt=\"\" src=\"images/lstm_words.png\" /></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "toy_data = ['Deep Learning sedikit menantang awalnya.','Bagaimana dengan akhirnya? :)',\n",
    "            'Dengan doa dan usaha Deep Learning sedikit demi sedikit akan dimengerti :)']\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(toy_data)\n",
    "sequences = tokenizer.texts_to_sequences(toy_data)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pad_sequences di Keras\n",
    "* Mirip VSM ==> kolom dengan panjang konstan\n",
    "* Tapi apa bedanya ya?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X = pad_sequences(sequences)\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Struktur datanya sudah siap untuk menjadi input untuk layer Word Embedding:\n",
    "\n",
    "<img alt=\"\" src=\"images/we.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "A = 15 # \"Lebih Besar\" dari Banyaknya \"kata unik\" di data training (= 14+1)\n",
    "B = 2 # Banyak neuron di layar embedding = panjang vektor representasi kata di WE\n",
    "# For simplicity reason, karena ini hanya \"toy data\" kita pakai = 2\n",
    "C = 11 # = X.shape[1] yaitu panjang vector \"pad_sequences\"\n",
    "model = Sequential()\n",
    "model.add(Embedding(A, B, input_length=C))\n",
    "# Selesai ... pada aplikasinya nanti layer embedding ini akan \"disambungkan\" dengan\n",
    "# Layer classifier DL. Namun untuk saat ini mari kita \"outputkan\" WE-nya seperti\n",
    "# yang kita lakukan sebelumnya di Gensim\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell ini hanya untuk \"mengintip\" hasil WE-nya\n",
    "model.compile('rmsprop', 'mse')\n",
    "WE = model.predict(X)\n",
    "print(WE.shape)\n",
    "WE # ==> It's a Tensor! ... Hence TensorFlow :)\n",
    "# The tensors are flowing throughout the layers and neurons\n",
    "# like river to the sea :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dengan Word Embeding Kata Tersebut dirubah menjadi angka\n",
    "\n",
    "* Bayangkan setiap kata menjadi vector\n",
    "* Sekumpulan kata (misal review) berarti sebuah Matrix.\n",
    "* Kumpulan Review berarti Tensor\n",
    "\n",
    "<h1 id=\"Kata-kata-tersebut-kemudian-dirubah-menjadi-vector-angka\">Kata-kata tersebut kemudian dirubah menjadi vector angka</h1>\n",
    "\n",
    "<ul>\n",
    "\t<li>Ingat saat pembahasan word embedding</li>\n",
    "\t<li><img alt=\"\" src=\"images/LSTM_kataAngka.gif\" style=\"width: 800px; height: 211px;\" /></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kembali ke Data Movie Review (IMDB) kita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))# Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data) # Our vectorized training data\n",
    "x_test = vectorize_sequences(test_data) # Our vectorized test data\n",
    "# Our vectorized labels\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network sederhana kita\n",
    "\n",
    "* Karena permasalahan kita sederhana kita bisa coba dengan bentuk jaringan sederhana terlebih dahulu: Layer Dense dan fungsi aktivasi ReLu\n",
    "* Parameter 16 di \"Dense\" artinya banyak hidden unit.\n",
    "* variasi parameter yang bisa dibuat: Berapa banyak layer? dan berapa banyak hidden unit?\n",
    "\n",
    "<img alt=\"\" src=\"images/3_layer_network.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apa itu Dense?\n",
    "\n",
    "<img alt=\"\" src=\"images/Sparse_Dense_Network.png\" style=\"width: 600px; height: 463px;\" />\n",
    "\n",
    "* Matematikawan menyebut ini \"Complete Graph\" di teori Graph.\n",
    "* Apa maksudnya \"Sequential\"? ==> _linear stack of layers_ [Mirip \"Lego\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse <=> Dropout\n",
    "\n",
    "<p><img alt=\"\" src=\"images/dropout.png\" style=\"width: 600px; height: 337px;\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fungsi Aktivasi\n",
    "\n",
    "<ul>\n",
    "\t<li>Sekedar merubah kodomain hasil summasi ke rentang nilai tertentu.</li>\n",
    "\t<li><img alt=\"\" src=\"images/act_func.png\" style=\"width: 760px; height: 206px;\" /></li>\n",
    "</ul>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/6_JST_Actv.png\" style=\"width: 756px; height: 625px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 > Contoh Fungsi tanh memetakan [-Inf, Inf] ke [-1, 1]</h1>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/tanh_act.gif\" style=\"width: 800px; height: 317px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 >Contoh 2: Fungsi Aktivasi Sigmoid yang bisa digunakan untuk menginat dan melupakan (mantan? :) )</h1>\n",
    "\n",
    "<ul>\n",
    "\t<li>Fungsi sigmoid mirip dengan tanh, namun intervalnya adalah [0, 1].</li>\n",
    "\t<li>Semakin dekat ke 0 ==&gt; melupakan (forget): informasi tidak relevan.</li>\n",
    "\t<li>Semakin dekat ke 1 ==&gt; mengingat: informasi relevan/penting.</li>\n",
    "\t<li><img alt=\"\" src=\"images/sigmoid.gif\" style=\"width: 800px; height: 317px;\" /></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# memangnya Tanpa fungsi aktivasi apa yang akan terjadi?\n",
    "\n",
    "* Tanpa fungsi aktivasi, weights bisa membesar tak berbatas ketika iterasinya berjalan\n",
    "\n",
    "<p><img alt=\"\" src=\"images/tanpa_tanh.gif\" style=\"width: 800px; height: 106px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dengan Fungsi Aktivasi, nilai weights selalu terbatas (misal) di -1 dan 1, namun tingkat kepentingan weight tetap terjaga.\n",
    "\n",
    "* Perhatikan nilai weight yang pertama\n",
    "<img alt=\"\" src=\"images/dgn_tanh.gif\" style=\"width: 800px; height: 106px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Layer - Perhatikan pada cell ini Network belum dijalankan, baru di define\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])\n",
    "\"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss, Optimizer, & metric\n",
    "\n",
    "<ol>\n",
    "\t<li><strong>Loss function (objective function)</strong> &mdash; fungsi yang akan di minimize. Hasilnya merepresentasikan tingkat sukses pada setiap iterasi.<br />\n",
    "\t<a href=\"https://keras.io/losses/\" target=\"_blank\">https://keras.io/losses/&nbsp;</a></li>\n",
    "\t<li><strong>Optimizer&nbsp;</strong>&mdash; Berfungsi untuk menentukan bagaimana (weights) di network akan di update berdasarkan loss-functionnya. (e.g. variasi dari SGD)<br />\n",
    "\t<a href=\"https://keras.io/optimizers/\" target=\"_blank\">https://keras.io/optimizers/</a></li>\n",
    "\t<li><strong>Metrics&nbsp;</strong>&mdash; Satuan evaluasi<br />\n",
    "\t<a href=\"https://keras.io/metrics/\" target=\"_blank\">https://keras.io/metrics/</a></li>\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Loss-function-and-Error\">Loss function and Error</h2>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/low-high-bias-variance.png\" style=\"width: 600px; height: 244px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memilih Fungsi Aktivasi dan Fungsi Loss\n",
    "\n",
    "<img alt=\"\" src=\"images/memilih_loss_dan_activation.png\" style=\"width: 600px; height: 368px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><big><strong>Binary Cross Entropy</strong></big></p>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/binary_cross_entropy.png\" style=\"width: 600px; height: 173px;\" /></p>\n",
    "\n",
    "<p><big><strong>Minimum Squared Error</strong></big></p>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/mse.png\" style=\"width: 300px; height: 106px;\" /></p>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/mse_mean.png\" style=\"width: 600px; height: 323px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" cellpadding=\"1\" cellspacing=\"1\" style=\"width: 500px\">\n",
    "\t<tbody>\n",
    "\t\t<tr>\n",
    "\t\t\t<td><img alt=\"\" src=\"images/contours_evaluation_optimizers.gif\" /></td>\n",
    "\t\t\t<td><img alt=\"\" src=\"images/saddle_point_evaluation_optimizers.gif\" /></td>\n",
    "\t\t</tr>\n",
    "\t</tbody>\n",
    "</table>\n",
    "\n",
    "Optimizer : \n",
    "<a href=\"http://ruder.io/optimizing-gradient-descent/\" target=\"_blank\">http://ruder.io/optimizing-gradient-descent/&nbsp;</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Di Deep learning Common Practicenya Data dibagi 3: \n",
    "# Training, Validation, dan Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apa ya Epoch di Deep Learning?\n",
    "\n",
    "<p><img alt=\"\" src=\"images/epoch.png\" style=\"width: 600px ; height: 230px\" /></p>\n",
    "\n",
    "## Saatnya Run model DL kita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DL baru dijalankan di cell ini\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Struktur Data, Struktur Data, Struktur Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "print(type(history_dict))\n",
    "history_dict.keys()\n",
    "# Tapi apa values dari dictionary ini?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sebaiknya di visualisasi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')# b is for \"solid blue line\"\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['binary_accuracy']\n",
    "val_acc_values = history_dict['val_binary_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bagaimana memaknai graphics diatas?\n",
    "\n",
    "### Stop di iterasi ke-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-Run dengan informasi sebelum ini\n",
    "# Dijadikan satu biar lebih jelas\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Akurasi 88.5 ... cukup baik, tapi can be better\n",
    "# Kita akan coba improve dengan LSTM di Sesi berikutnya.\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jika kita ingin prediksi ke Data Test\n",
    "prediksi = model.predict(x_test)\n",
    "prediksi[:7]\n",
    "# beberapa prediksi sangat yakin = 0.9999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latihan (hingga selesai waktu Sesi ke-02)\n",
    "\n",
    "* Coba hidden layers 1 dan 3 ... Mana yang terbaik?\n",
    "* Sebelumnya kita menggunakan 16 unit, coba 8, 32, dan 64. Apa akibatnya?\n",
    "* Coba tanh ketimbang relu sebagai fungsi aktivasinya. Apakah lebih baik?\n",
    "* Coba dengan data Lain, misal data dibawah ini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset dari Modul\n",
    "contoh dataset dokumen lain yang cukup tenar: &quot;20 NewsGroup&quot;\n",
    "\n",
    "<img alt=\"\" src=\"images/6_20News.jpg\" style=\"height: 300px ; width: 533px\" />\n",
    "<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups\" target=\"_blank\">http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups</a></p>\n",
    "\n",
    "<p><strong>Categories </strong>=&nbsp;</p>\n",
    "<pre>\n",
    "[&#39;alt.atheism&#39;, &#39;comp.graphics&#39;, &#39;comp.os.ms-windows.misc&#39;, &#39;comp.sys.ibm.pc.hardware&#39;, &#39;comp.sys.mac.hardware&#39;,\n",
    " &#39;comp.windows.x&#39;, &#39;misc.forsale&#39;, &#39;rec.autos&#39;, &#39;rec.motorcycles&#39;, &#39;rec.sport.baseball&#39;, &#39;rec.sport.hockey&#39;,\n",
    " &#39;sci.crypt&#39;, &#39;sci.electronics&#39;, &#39;sci.med&#39;, &#39;sci.space&#39;, &#39;soc.religion.christian&#39;, &#39;talk.politics.guns&#39;,\n",
    " &#39;talk.politics.mideast&#39;, &#39;talk.politics.misc&#39;, &#39;talk.religion.misc&#39;]</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Petunjuk : Gunakan cara merubah text ke Pad-Sequence seperti yang sudah dibahas sebelumnya.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "try:\n",
    "    f = open('data/20newsgroups_bin.pckl', 'rb') # Menghindari downloading data berkali-kali\n",
    "    Y, D = pickle.load(f); f.close()\n",
    "except:\n",
    "    categories = ['talk.politics.misc',  'rec.autos']\n",
    "    data = fetch_20newsgroups(subset='train', categories=categories,remove=('headers', 'footers', 'quotes'))\n",
    "    Y = data.target\n",
    "    D = [doc for doc in data.data]\n",
    "    f = open('data/20newsgroups_bin.pckl', 'wb') # save ke lokal drive\n",
    "    pickle.dump((Y, D), f); f.close()\n",
    "    \n",
    "'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jawaban disini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>End of Module Implementasi Deep Learning 01</h1>\n",
    "\n",
    "<hr />\n",
    "<img alt=\"\" src=\"images/DL_meme.jpg\"/>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
