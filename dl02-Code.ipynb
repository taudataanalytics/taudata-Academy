{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1><strong>taudata Analytics</strong></h1></center>\n",
    "<center><h2><strong><font color=\"blue\">DL 02 - Pendahuluan PyTorch & Tensor</font></strong></h2></center>\n",
    "<img alt=\"\" src=\"images/covers/taudata-cover.jpg\"/>\n",
    "\n",
    "<b><center>(C) Taufik Sutanto</center>\n",
    "<center><h3><font color=\"blue\">module: https://taudata.blogspot.com/2022/04/dl-02.html</font></h3></center>\n",
    "<center><h3><font color=\"blue\">Video Penjelasan: https://youtu.be/nLINKnoIl40 </font></h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Module\n",
    "import torch, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Numpy and Pytorch versions = 1.21.5, 1.11.0+cu113\n",
      "Using device: cuda, NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Currently Memory Allocated, Cached = 0.0 GB,  0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Kalau saya sukanya cek versi dan apakah PyTorch (atau tensorflow) sudah dapat mengakses GPU atau belum\n",
    "print(\"Using Numpy and Pytorch versions = {}, {}\".format(np.__version__, torch.__version__))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device, end=', ')\n",
    "if device.type == 'cuda': #Additional Info when using cuda\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Currently Memory Allocated, Cached =', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB, ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor dari Python List\n",
    "\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2]), 'torch.LongTensor')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape, x_data.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=0.001, min=-65504, max=65504, eps=0.000976562, tiny=6.10352e-05, dtype=float16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.finfo(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], dtype=torch.int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor dari Numpy\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.6655, 0.1963],\n",
      "        [0.0498, 0.6696]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ukuran  & property (shape, datatype) sama, tapi element berbeda.\n",
    "#  unless explicitly overridden.\n",
    "\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2]), 'torch.LongTensor')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ones.shape, x_ones.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warning on \"Device\" and \"Dtype\"\n",
    "\n",
    "* Jika memang ingin menjalankan DL kita di GPU, maka sangat penting secara eksplisit menetapkan Tipe dan Device\n",
    "* Terutama pada input variabel DL kita.\n",
    "* Data di device yang tepat DAN Model yang dijalankan di GPU adalah kunci sukses menjalankan DL-nya di GPU\n",
    "* Misal kelak kita akan menggunakan perintah berikut: \n",
    " - model = torch.nn.Sequential(*modules).to(device)\n",
    " - Begitu juga pada Grad Function di DL kita nanti.\n",
    "\n",
    "### Contoh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "# diatas sebenarnya ini sudah di define, diulang utk mempertegas\n",
    "\n",
    "# instead of \n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)\n",
    "\n",
    "# Sebaiknya lakukan ini jika memang ingin menjalankan DL di GPU\n",
    "x_data = torch.tensor(data, dtype=dtype, device=device)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warning 2\n",
    "\n",
    "* Jika DL sudah selesai, Tensor yang ada di GPU tidak bisa langsung di convert ke Numpy.\n",
    "* Harus di copy ke CPU terlebih dahulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    xx = x_data.detach().numpy()\n",
    "    print(xx)\n",
    "except Exception as err_:\n",
    "    print(err_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What we should do instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    xx = x_data.cpu().detach().numpy()\n",
    "    print(xx)\n",
    "except Exception as err_:\n",
    "    print(err_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.5431, 0.7966, 0.5175],\n",
      "        [0.7834, 0.5468, 0.5039]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# dimensi Tensor adalah Tuple\n",
    "\n",
    "shape = (2, 3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check Tensor ada dimana\n",
    "tensor = torch.rand(3, 4)\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Bisa pindah ke GPU ... perhatikan kita bisa punya >1 GPU, index GPU mulai dari 0\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "    print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  0.,  1.,  1.],\n",
      "        [-2., -2., -2., -2.],\n",
      "        [ 1.,  0.,  1.,  1.],\n",
      "        [ 1.,  0.,  1., 99.]])\n"
     ]
    }
   ],
   "source": [
    "# Slicing Tensor = Numpy\n",
    "tensor = torch.ones(4, 4)\n",
    "tensor[:,1] = 0.0\n",
    "tensor[1,:] = -2.0\n",
    "tensor[-1,-1] = 99.0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.],\n",
      "        [-2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.],\n",
      "        [ 1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.],\n",
      "        [ 1.,  0.,  1., 99.,  1.,  0.,  1., 99.,  1.,  0.,  1., 99.]])\n"
     ]
    }
   ],
   "source": [
    "# Operasi Concatenasi (dan operasi lainnya) juga mirip dengan Numpy\n",
    "\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.mul(tensor) \n",
      " tensor([[1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.0000e+00, 4.0000e+00, 4.0000e+00, 4.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 1.0000e+00, 9.8010e+03]]) \n",
      "\n",
      "tensor * tensor \n",
      " tensor([[1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.0000e+00, 4.0000e+00, 4.0000e+00, 4.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 1.0000e+00, 9.8010e+03]])\n"
     ]
    }
   ],
   "source": [
    "# Operasi Tensor = Numpy, berarti element Wise ... Hati-hati tidak seperti Matlab.\n",
    "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor * tensor \\n {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.matmul(tensor.T) \n",
      " tensor([[ 3.0000e+00, -6.0000e+00,  3.0000e+00,  1.0100e+02],\n",
      "        [-6.0000e+00,  1.6000e+01, -6.0000e+00, -2.0200e+02],\n",
      "        [ 3.0000e+00, -6.0000e+00,  3.0000e+00,  1.0100e+02],\n",
      "        [ 1.0100e+02, -2.0200e+02,  1.0100e+02,  9.8030e+03]]) \n",
      "\n",
      "tensor @ tensor.T \n",
      " tensor([[ 3.0000e+00, -6.0000e+00,  3.0000e+00,  1.0100e+02],\n",
      "        [-6.0000e+00,  1.6000e+01, -6.0000e+00, -2.0200e+02],\n",
      "        [ 3.0000e+00, -6.0000e+00,  3.0000e+00,  1.0100e+02],\n",
      "        [ 1.0100e+02, -2.0200e+02,  1.0100e+02,  9.8030e+03]])\n"
     ]
    }
   ],
   "source": [
    "# Perkalian Matrix\n",
    "\n",
    "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  0.,  1.,  1.],\n",
      "        [-2., -2., -2., -2.],\n",
      "        [ 1.,  0.,  1.,  1.],\n",
      "        [ 1.,  0.,  1., 99.]]) \n",
      "\n",
      "tensor([[  6.,   5.,   6.,   6.],\n",
      "        [  3.,   3.,   3.,   3.],\n",
      "        [  6.,   5.,   6.,   6.],\n",
      "        [  6.,   5.,   6., 104.]])\n"
     ]
    }
   ],
   "source": [
    "# Tanda \"_\" artinya operasi \"inplace\" ... ini penting untuk diingat untuk menekan memory. Terutama di GPU\n",
    "\n",
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Tentu saja Tensor dapat diubah kembali kke numpy\n",
    "# Coba sampaikan di kolom komentar, kira-kira kapan kita butuh hal ini?\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Tapi \"reference to variable\" seperti di adsp-01 tetap berlaku (pythonic)\n",
    "# perubahan di t akan merubah n\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tapi kalau Tensor ada di GPU jadi agak beda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], device='cuda:0')\n",
      "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5, dtype=dtype, device=device)\n",
    "print(t)\n",
    "\n",
    "try:\n",
    "    print(t.numpy())\n",
    "except Exception as err_:\n",
    "    print(err_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What we need to do instead\n",
    "\n",
    "* Pindahkan ke CPU dulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], device='cuda:0')\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5, dtype=dtype, device=device)\n",
    "print(t)\n",
    "\n",
    "try:\n",
    "    print(t.cpu().numpy())\n",
    "except Exception as err_:\n",
    "    print(err_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hati-hati Tensor (GPU) hanya bisa diaplikasikan ke fungsi di Torch\n",
    "\n",
    "* Alternativenya juggle ke numpy CPU (seperti di cell sebelumnya), tapi ini biasanya mempengaruhi performa.\n",
    "* Sebaiknya gunakan fungsi Torch saja.\n",
    "* Fungsi Torch juga wajib menggunakan parameter input tensor (error jika input = array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n",
      "Torch Function:  tensor([0.8415, 0.8415, 0.8415, 0.8415, 0.8415], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5, dtype=dtype, device=device)\n",
    "\n",
    "try:\n",
    "    print(\"Numpy (CPU) Function: \", np.sin(t))\n",
    "except Exception as err_:\n",
    "    print(err_)\n",
    "    \n",
    "try:\n",
    "    print(\"Torch Function: \", torch.sin(t))\n",
    "except Exception as err_:\n",
    "    print(err_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sin(): argument 'input' (position 1) must be Tensor, not numpy.ndarray\n"
     ]
    }
   ],
   "source": [
    "# Torch Function only works for tensors\n",
    "t = np.ones(5)\n",
    "try:\n",
    "    print(\"Torch Function: \", torch.sin(t))\n",
    "except Exception as err_:\n",
    "    print(err_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elemen terakhir t tensor(1., device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# perbandingan logic tensor dan Float masih bisa dilakukan\n",
    "t = torch.ones(5, dtype=dtype, device=device)\n",
    "\n",
    "print(\"elemen terakhir t\", t[-1])\n",
    "\n",
    "try:\n",
    "    print(t[-1]>2.0)\n",
    "except Exception as err_:\n",
    "    print(err_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n"
     ]
    }
   ],
   "source": [
    "# Tapi walau t[-1] adalah sebuah nilai, tapi ini tetap tensor sehingga ... \n",
    "# Expected karena numpy ndak bisa bekerja di GPU (tensor)\n",
    "try:\n",
    "    print(np.isnan(t[-1]))\n",
    "except Exception as err_:\n",
    "    print(err_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(t[-1].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perhatikan bahwa konversi diatas adalah Copy memory (GPU & CPU)\n",
    "\n",
    "* Jika mau memindahkan Tensor dan mengeluarkannya dari Computational Graph-nya PyTorch maka gunakan perintah **Detach**\n",
    "* Detach juga digunaan jika tensor kita punya attribut Grad, dengan kata lain kita tidak bisa convert ke numpy jika tensornya punya attribut **\"grad\"**.\n",
    "* Jika konsep **grad** membingungkan jangan hawatir, module setelah ini akan membahas hal ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t.cpu().detach().numpy()\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten .. Bukan karena Bumi itu datar :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n",
      "\n",
      "[1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[[1, 2],\n",
    "                    [3, 4]],\n",
    "                   [[5, 6],\n",
    "                    [7, 8]]])\n",
    "print(t, end='\\n\\n')\n",
    "print(t.flatten().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catatan Penting terakhir\n",
    "\n",
    "* Beberapa model DL yang ada terkadang \"menipu\", karena sebenarnya modelnya sensitive terhadap initial weights namun tidak dilaporkan.\n",
    "* Sebaiknya minimal selalu Gunakan Seed di awal code DL kita:\n",
    "* Nilai seed bebas, biasanya by default adalah 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d288b743b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\"> Akhir Modul DL 02 - Pendahuluan PyTorch untuk Deep learning</font></center>\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
