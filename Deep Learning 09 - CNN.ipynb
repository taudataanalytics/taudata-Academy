{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2><strong><font color=\"blue\">Deep learning 09 - Computer Vision - CNN to Yolo</font></strong></h2></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/covers/cover_taudata_uin.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2><strong><font color=\"blue\">Referensi</font></strong></h2></center>\n",
    "\n",
    "\n",
    "* https://www.youtube.com/watch?v=HGwBXDKFk9I\n",
    "* https://medium.com/analytics-vidhya/yolo-explained-5b6f4564f31\n",
    "* Paper Original Yolo: https://arxiv.org/pdf/1506.02640v5.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2><strong><font color=\"blue\">Aplikasi Computer Vision</font></strong></h2></center>\n",
    "\n",
    "\n",
    "<img alt=\"\" src=\"images/DL/machine learning classification applications.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2><strong><font color=\"blue\">...</font></strong></h2></center>\n",
    "\n",
    "\n",
    "1. \n",
    "\n",
    "\n",
    "<img alt=\"\" src=\"images/DL/Riwayat-CNN.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Convolutional Neural Networks (CNN)</font></center>\n",
    "\n",
    "* Convolutional Neural Networks (CNN) asalnya dari bidang image processing.\n",
    "* CNN menggunakan “filter” atas data dan menghitung \"representasi\" bentuk baru yang lebih efisien.\n",
    "* Walau di perkenalkan di bidang image processing, CNN juga dapat digunakan di data teks dan pada beberapa literatur menunjukkan bahwa CNN di data teks bekerja dengan cukup baik.\n",
    "* Video penjelasan lebih lanjut: https://www.youtube.com/watch?v=jajksuQW4mc\n",
    "* Keterangan lain: https://medium.com/data-folks-indonesia/pemahaman-dasar-convolutional-neural-networks-bfa1bf0b06e1\n",
    "\n",
    "<img alt=\"\" src=\"images/DL/cnn convolutional neural network.jpeg\" style=\"height: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Memahami Convolutional Neural Networks (CNN) - 01: image structure</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/DL/cnn_digital_photo_data_Structure.png\" style=\"height: 400px;\"/>\n",
    "\n",
    "https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Memahami Convolutional Neural Networks (CNN) - 02: Definisi</font></center>\n",
    "\n",
    "* It is a process where we take a small matrix of numbers (called kernel or filter), we pass it over our image and transform it based on the values from filter. \n",
    "* Subsequent feature map values are calculated according to the following formula, where the input image is denoted by f and our kernel by h. \n",
    "* The indexes of rows and columns of the result matrix are marked with m and n respectively.\n",
    "\n",
    "<img alt=\"\" src=\"images/DL/cnn convolutional neural network formula.gif\" style=\"height: 100px;\"/>\n",
    "\n",
    "https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" src=\"images/DL/cnn convolutional neural network.gif\" style=\"height: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Memahami Convolutional Neural Networks (CNN) - 03: Effect</font></center>\n",
    "\n",
    "* After placing our filter over a selected pixel, we take each value from kernel and multiply them in pairs with corresponding values from the image. Finally we sum up everything and put the result in the right place in the output feature map. \n",
    "* Above we can see how such an operation looks like in micro scale, but what is even more interesting, is what we can achieve by performing it on a full image.\n",
    "\n",
    "<img alt=\"\" src=\"images/DL/cnn convolutional neural network effect.gif\" style=\"height: 400px;\"/>\n",
    "\n",
    "https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Memahami Convolutional Neural Networks (CNN) - 04: Effect continued</font></center>\n",
    "\n",
    "* when we perform convolution over the 6x6 image with a 3x3 kernel, we get a 4x4 feature map. This is because there are only 16 unique positions where we can place our filter inside this picture. \n",
    "* Since our image shrinks every time we perform convolution, we can do it only a limited number of times, before our image disappears completely. \n",
    "* What’s more, if we look at how our kernel moves through the image we see that the impact of the pixels located on the outskirts is much smaller than those in the center of image. \n",
    "* This way we lose some of the information contained in the picture. Below you can see how the position of the pixel changes its influence on the feature map.\n",
    "\n",
    "<img alt=\"\" src=\"images/DL/cnn convolutional neural network effect 02.gif\" style=\"height: 400px;\"/>\n",
    "\n",
    "https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Memahami Convolutional Neural Networks (CNN) - 05: Max Pooling</font></center>\n",
    "\n",
    "* creating a mask that remembers the position of the values used in the first phase, which we can later utilize to transfer the gradients.\n",
    "\n",
    "<img alt=\"\" src=\"images/DL/cnn convolutional neural network Max Pooling.gif\" style=\"height: 400px;\"/>\n",
    "\n",
    "https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Kasus CIFAR-10</font></center>\n",
    "\n",
    "* CIFAR-10 dataset terdiri dari 60,000 gambar berwarna dalam 10 kelas, dengan 6,000 gambar per kelas. Dataset ini sudah tersedia di dalam library torchvision.\n",
    "* The CIFAR-10 dataset (Canadian Institute for Advanced Research, 10 classes) is a subset of the Tiny Images dataset and consists of 60000 32x32 color images. The images are labelled with one of 10 mutually exclusive classes: airplane, automobile (but not truck or pickup truck), bird, cat, deer, dog, frog, horse, ship, and truck (but not pickup truck). There are 6000 images per class with 5000 training and 1000 testing images per class.\n",
    "* https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "<img alt=\"\" src=\"images/DL/CiFar-10-Dataset.png\" style=\"height: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-30T05:59:04.328620Z",
     "start_time": "2022-09-30T05:59:04.310605Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Modules untuk Notebook ini\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "try:\n",
    "    import google.colab; IN_COLAB = True\n",
    "    print(\"Installing the required modules\")\n",
    "    !pip install torch torchvision torchsummary opencv-python yolov5\n",
    "    #!wget https://raw.githubusercontent.com/taudata...\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running the code locally, please make sure all the python module versions agree with colab environment and all data/assets downloaded\")\n",
    "    \n",
    "import numpy as np, torch, torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed=seed)\n",
    "\"Modules Loaded\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Load Dataset</font></center>\n",
    "\n",
    "### <center><font color=\"red\">Hati-hati akan mendownload data images yang cukup besar ~170MB</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/DL/...\" style=\"height: 1px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformasi data: konversi ke Tensor dan normalisasi\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Download dan load dataset CIFAR-10\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,  download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,  shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "type(trainset), type(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Arsitektur CNN</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/DL/...\" style=\"height: 1px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = SimpleCNN()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Loss Function dan Optimizer</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/DL/...\" style=\"height: 1px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Training</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/DL/...\" style=\"height: 1px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTraining = 5\n",
    "\n",
    "for epoch in range(nTraining):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Prediksi</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/DL/...\" style=\"height: 1px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Akurasi </font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/DL/...\" style=\"height: 1px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">You Only Look Once (YOLO)</font></center>\n",
    "\n",
    "* Paper Original Yolo: https://arxiv.org/pdf/1506.02640v5.pdf\n",
    "* Untuk membuat kode YOLO (You Only Look Once) yang paling sederhana dengan Python, kita bisa menggunakan pustaka YOLOv5 dari Ultralytics, yang merupakan implementasi populer dan open-source dari algoritma YOLO.\n",
    "* Module yang dibutuhkan torch, opencv-python, dan yolov5\n",
    "* Ultralytics menyediakan model yang sudah dilatih yang bisa kita gunakan langsung.\n",
    "* Versi terakhir saat module ini dibuat: YOLO 8.2, Versi 9.0 (Training & Development)\n",
    "* https://docs.ultralytics.com/#yolo-a-brief-history\n",
    "* Kita bisa melakukan train pada data baru pada versi 8 atau menggunakan pre-trained model: https://docs.ultralytics.com/usage/python/#using-trainers\n",
    "* Pada kesempatan ini kita akan menggunakan pre-trained model.\n",
    "\n",
    "<img alt=\"\" src=\"images/DL/yolo.png\" style=\"height: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Muat model YOLOv5 yang sudah dilatih\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Fungsi Untuk Deteksi Gambar</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/DL/...\" style=\"height: 1px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image_path):\n",
    "    # Baca gambar\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Deteksi objek\n",
    "    results = model(img)\n",
    "\n",
    "    # Gambar hasil deteksi pada gambar asli\n",
    "    results.render()  # Render hasil deteksi pada gambar\n",
    "\n",
    "    # Konversi kembali ke BGR untuk OpenCV\n",
    "    img_with_boxes = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Tampilkan gambar dengan bounding box\n",
    "    plt.imshow(img_with_boxes)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Jika ingin menyimpan hasilnya\n",
    "    cv2.imwrite('output.jpg', img_with_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Deteksi Gambar</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'data/uin.JPG'  # Contoh Gambar\n",
    "detect_objects(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\"> Akhir Modul </font></center>\n",
    "\n",
    "<hr />\n",
    "<img alt=\"\" src=\"images/meme-cartoon/CNN-meme.jpeg\" style=\"height: 400px;\"/>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
