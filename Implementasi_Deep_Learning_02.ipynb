{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img alt=\"\" src=\"images/Cover_UnMuh_2021.png\"/></center> \n",
    "\n",
    "# <center><font color=\"black\">Implementasi Deep Learning Bagian ke-02 <br> http://bit.ly/unmuh-B-2021</font></center>\n",
    "## <center><font color=\"black\">(C) Taufik Sutanto - 2021 <br> tau-data Indonesia ~ https://tau-data.id/</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color=\"blue\">Outline Module Implementasi B :</font>\n",
    "\n",
    "* LSTM & Multiklasifikasi\n",
    "* Deep Learning for Computer Vision: Cat vs Dog\n",
    "* Some DL Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing some supporting libraries\n",
    "import pickle, numpy as np, warnings; warnings.simplefilter('ignore')\n",
    "!mkdir data\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version = \", tf.__version__)\n",
    "if tf.test.is_built_with_cuda():\n",
    "    physical_devices = tf.config.list_physical_devices('GPU') \n",
    "    print(\"CUDA enabled TF, Num GPUs:\", len(physical_devices), physical_devices) \n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sequence?\n",
    "\n",
    "<ul>\n",
    "\t<li>Misal diberikan gambar(data) sebuah bola berikut.</li>\n",
    "\t<li>Silahkan prediksi ke arah mana kira-kira bola tersebut akan bergulir.</li>\n",
    "\t<li>Ada masalah?</li>\n",
    "\t<li><img alt=\"\" src=\"images/still_ball.png\" style=\"width: 193px ; height: 183px\" /></li>\n",
    "\t<li>Seberapa baik prediksi kita?</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting in sequence data\n",
    "\n",
    "<ul>\n",
    "\t<li>Sekarang jika kita memiliki informasi historis pergerakan bola tersebut, apakah prediksinya lebih mudah?</li>\n",
    "\t<li><img alt=\"\" src=\"images/rolling_ball.gif\" style=\"width: 480px; height: 270px;\" /></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Contoh-Sequence-Data\">Contoh Sequence Data</h1>\n",
    "\n",
    "<ul>\n",
    "\t<li>DNA, Audio, Texts, etc</li>\n",
    "\t<li><img alt=\"\" src=\"images/seq_data.jpg\" style=\"width: 800px; height: 251px;\" /></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hal Menarik Tentang data sequence?\n",
    "\n",
    "* Coba sebutkan urutan Alphabet ... (biasanya sambil nyanyi :) )\n",
    "\n",
    "A, B, C, D, ..., X, Y, Z\n",
    "\n",
    "* Sekarang coba lakukan dalam urutan sebaliknya\n",
    "\n",
    "Z, Y, X, ..., C, B, D\n",
    "\n",
    "* Menariknya sekarang coba lakukan mulai dari Huruf \"G\"\n",
    "\n",
    "G, ... , X, Y, Z\n",
    "\n",
    "* Otak kita cepat menangkap suatu pola urutan tertentu, Di Deep learning RNN mengikuti filosofi/cara kerja ini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Recurrent-Neural-Networks-(RNN)\">Recurrent Neural Networks (RNN)</h1>\n",
    "\n",
    "<ul>\n",
    "\t<li>RNN adalah model network yang biasa digunakan untuk menangani dalam bentuk sequence (barisan) seperti text atau suara.</li>\n",
    "\t<li>Jika NN biasa dapat dibayangkan sebagai &quot;graph sederhana&quot; RNN adalah graph/network dengan loop.</li>\n",
    "\t<li>Loop tersebut adalah mekanisme RNN untuk menghandle data berbentuk sequence</li>\n",
    "\t<li>Di setiap neuron bisa menyimpan informasi dari input sebelumnya</li>\n",
    "</ul>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/rnn.png\" style=\"width: 615px; height: 168px;\" /></p>\n",
    "\n",
    "* $x_t$ vector input, $A$ bagian dari RNN, dan $h_t$ vector output.\n",
    "* $h_t$ kemudian dibandingkan dengan nilai sesungguhnya (label) untuk mendapatkan network error, lalu mengupdate nilai weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"NN-(biasa:-Feed-Forward-NN)-VS-RNN\">NN (biasa: Feed Forward NN) VS RNN</h1>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/NN_VS_RNN.png\" style=\"width: 387px; height: 245px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Recurrent-Neural-Networks-(RNN)\">Recurrent Neural Networks (RNN)</h1>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/RNN.gif\" style=\"width: 250px; height: 250px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tipe RNN\n",
    "\n",
    "<p>Ada 3 Tipe RNN yang paling populer:</p>\n",
    "\n",
    "<ul>\n",
    "\t<li>vanilla RNN,</li>\n",
    "\t<li>long short-term memory (LSTM), proposed by Hochreiter and Schmidhuber in 1997, and</li>\n",
    "\t<li>gated recurrent units (GRU), proposed by Cho et. al in 2014.</li>\n",
    "</ul>\n",
    "\n",
    "Selain itu:\n",
    "<p><img alt=\"\" src=\"images/rnn_arch.png\" style=\"width: 783px; height: 712px;\" /></p>\n",
    "<p>* Source: https://www.rsisinternational.org/journals/ijrsi/digital-library/volume-5-issue-3/124-129.pdf</p>\n",
    "\n",
    "## Kita akan bahas lebih dalam tentang LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mengapa LSTM? Vanishing Gradient di RNN menyebabkan penurunan akurasi pada data sequential\n",
    "\n",
    "<ul>\n",
    "\t<li>Bahkan manusia akan sulit untuk menginterpreatsikan hanya frase &quot;is it?&quot;</li>\n",
    "\t<li><img alt=\"\" src=\"images/VG_Dori.png\" style=\"width: 460px; height: 530px;\" /></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ilustrasi Cara Kerja LSTM: Studi Kasus Review Produk\n",
    "\n",
    "<p><img alt=\"\" src=\"images/ilustrasi_review.jpg\" style=\"width: 566px; height: 407px;\" /></p>\n",
    "\n",
    "* Ketika membaca review seperti ini, otak kita automatis mengingat kata-kata kunci yang penting yang merupakan inti dari reviewnya.\n",
    "\n",
    "* Seringnya kita tidak mengingat dan bahkan tidak perlu mengingat seluruh kata-kata pada review untuk memahami reviewnya.\n",
    "* Kemungkinan besar otak kita akan menangkap kata-kata: \"amazing\", \"will buy again\" dsb.\n",
    "* kata-kata yang menurut otak kita kurang penting seperti of, should, all, dan detail (stopwords) lainnya kemungkinan besar akan dilupakan (forget) oleh otak kita tidak lama setelah membaca. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Cara-Kerja-LSTM\">Cara Kerja LSTM</h1>\n",
    "\n",
    "<ul>\n",
    "\t<li>Melupakan informasi yang tidak relevant.</li>\n",
    "\t<li><img alt=\"\" src=\"images/ilustrasi_review_lstm.jpg\" style=\"width: 560px; height: 403px;\" /></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM adalah salah satu solusi dari RNN biasa untuk masalah Vanishing Gradient\n",
    "\n",
    "<ul>\n",
    "\t<li>Penjelasan yang baik tentang LSTM:&nbsp;http://colah.github.io/posts/2015-08-Understanding-LSTMs/</li>\n",
    "\t<li>Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8), 1735-1780.</li>\n",
    "\t<li><a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.676.4320&amp;rep=rep1&amp;type=pdf\" target=\"_blank\">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.676.4320&amp;rep=rep1&amp;type=pdf</a></li>\n",
    "\t<li><img alt=\"\" src=\"images/lstm_wiki.png\" style=\"width: 800px; height: 446px;\" /></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Cara-kerja-LSTM\">Cara kerja LSTM</h1>\n",
    "\n",
    "<ul>\n",
    "\t<li>Mirip dengan penjelasan diatas, namun dengan perbedaan perhitungan internalnya.</li>\n",
    "\t<li><img alt=\"\" src=\"images/crKerja_LSTM.png\" style=\"width: 787px ; height: 452px\" /></li>\n",
    "\t<li>Masih ingat makna &quot;point wise&quot; waktu di modul 1? ... :)</li>\n",
    "\t<li>Operasi-operasi ini yang mengakibatkan LSTM dapat mengingat dan melupakan.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ketika prosesnya berlangsung hidden state sebelumnya diteruskan (pass) ke sequence selanjutnya.</h2>\n",
    "\n",
    "<ul>\n",
    "\t<li>Hidden state bertindak sebagai neural networks memory. Ia menyimpan data sebelumnya yang pernah di proses.</li>\n",
    "\t<li><img alt=\"\" src=\"images/LSTM_PassHidden_State.gif\" style=\"width: 800px; height: 211px;\" /></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Bagaimana-perhitungannya-dilakukan?\">Bagaimana perhitungannya dilakukan?</h1>\n",
    "\n",
    "<ul>\n",
    "\t<li>Pertama-tama input dan hidden state sebelumnyya dikombinasikan untuk membentuk sebuah vektor.</li>\n",
    "\t<li>Vectornya kemudian masuk ke fungsi aktivasi <strong>tanh</strong>, outputnya adalah hidden state (network&#39;s memory).</li>\n",
    "\t<li><img alt=\"\" src=\"images/LSTM_hitung_tanh.gif\" style=\"width: 800px; height: 317px;\" /></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Forget-gate\">Forget gate</h1>\n",
    "\n",
    "<ul>\n",
    "\t<li>Gate ini menentukan informasi mana yang disimpan dan dibuang.</li>\n",
    "\t<li>Informasi dari hidden state sebelumnya dan informasi input saat ini dilanjutkan ke fungsi sigmoid.</li>\n",
    "\t<li>Seperti yang dijelaskan sebelumnya, jika nilainya mendekati 0: forget dan 1: keep</li>\n",
    "\t<li><img alt=\"\" src=\"images/forget_gate.gif\" style=\"width: 800px; height: 421px;\" /></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Input-Gate\">Input Gate</h1>\n",
    "\n",
    "<ul>\n",
    "\t<li>Input gate digunakan untuk mengupdate cell state.</li>\n",
    "\t<li>Pertama-tama hidden state pada proses sebelumnya dan input vektor saat ini di teruskan ke fungsi sigmoid.</li>\n",
    "\t<li>0: not important, 1: important</li>\n",
    "\t<li>hidden state+ input juga dimasukkan ke tanh</li>\n",
    "\t<li>output sigmoid dan tanh dikalikan (multiply)</li>\n",
    "\t<li>\n",
    "\t<p>Output sigmoid akan menentukan informasi dari tanh output mana yang akan di simpan.</p>\n",
    "\t</li>\n",
    "\t<li><img alt=\"\" src=\"images/input_gate.gif\" style=\"width: 800px; height: 379px;\" /></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Cell-State\"><img alt=\"\" src=\"images/cell_state.gif\" style=\"width: 800px; height: 421px;\" />Cell State</h1>\n",
    "\n",
    "<ul>\n",
    "\t<li>Cell State dikalikan (point wise) dengan forget vector.</li>\n",
    "\t<li>cell state bisa hilang jika dikalikan dengan nilai mendekati 0.</li>\n",
    "\t<li>\n",
    "\t<p>output dari input gate di jumlahkan untuk melakukan update cell state.</p>\n",
    "\t</li>\n",
    "\t<li>&nbsp;</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Output-Gate\">Output Gate</h1>\n",
    "\n",
    "<ul>\n",
    "\t<li>Output gate menentukan hidden state selanjutnya.</li>\n",
    "\t<li>Hidden state memuat informasi dari input sebelumnya dan juga digunakan untuk prediksi.</li>\n",
    "\t<li>hidden state sebelumnya dan input saat ini masuk ke sigmoid kemudian ke tanh.</li>\n",
    "\t<li>Kalikan output tanh dan sigmoid untuk menentukan informasi hidden state.</li>\n",
    "\t<li>Outputnya adalah hidden state baru.</li>\n",
    "\t<li>\n",
    "\t<p>Cell state dan hidden state baru dilanjutkan ke iterasi selanjutnya.</p>\n",
    "\t</li>\n",
    "\t<li><img alt=\"\" src=\"images/output_gate.gif\" style=\"width: 800px; height: 379px;\" /></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secara Matematis:\n",
    "\n",
    "<p><img alt=\"\" src=\"images/lstm_math.png\" style=\"width: 800px; height: 262px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Aplikasi-Aplikasi-RNN\">Aplikasi-Aplikasi RNN</h1>\n",
    "\n",
    "<ul>\n",
    "\t<li><a href=\"https://en.wikipedia.org/wiki/Machine_Translation\" title=\"Machine Translation\">Machine Translation</a></li>\n",
    "\t<li><a href=\"https://en.wikipedia.org/wiki/Robot_control\" title=\"Robot control\">Robot control</a><sup id=\"cite_ref-77\"><a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-77\">[77]</a></sup></li>\n",
    "\t<li><a href=\"https://en.wikipedia.org/wiki/Time_series_prediction\" title=\"Time series prediction\">Time series prediction</a><sup id=\"cite_ref-78\"><a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-78\">[78]</a></sup></li>\n",
    "\t<li><a href=\"https://en.wikipedia.org/wiki/Speech_recognition\" title=\"Speech recognition\">Speech recognition</a><sup id=\"cite_ref-79\"><a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-79\">[79]</a></sup><sup id=\"cite_ref-80\"><a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-80\">[80]</a></sup><sup id=\"cite_ref-graves2013_81-0\"><a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-graves2013-81\">[81]</a></sup></li>\n",
    "\t<li><a href=\"https://en.wikipedia.org/wiki/Speech_synthesis\" title=\"Speech synthesis\">Speech synthesis</a></li>\n",
    "\t<li>Time series anomaly detection<sup id=\"cite_ref-82\"><a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-82\">[82]</a></sup></li>\n",
    "\t<li>Rhythm learning<sup id=\"cite_ref-peephole2002_83-0\"><a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-peephole2002-83\">[83]</a></sup></li>\n",
    "\t<li>Music composition<sup id=\"cite_ref-84\"><a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-84\">[84]</a></sup></li>\n",
    "\t<li>Grammar learning<sup id=\"cite_ref-85\"><a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-85\">[85]</a></sup><sup id=\"cite_ref-peepholeLSTM_86-0\"><a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-peepholeLSTM-86\">[86]</a></sup><sup id=\"cite_ref-87\"><a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-87\">[87]</a></sup></li>\n",
    "\t<li><a href=\"https://en.wikipedia.org/wiki/Handwriting_recognition\" title=\"Handwriting recognition\">Handwriting recognition</a><sup id=\"cite_ref-88\"><a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-88\">[88]</a></sup><sup id=\"cite_ref-89\"><a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-89\">[89]</a></sup></li>\n",
    "\t<li>Human action recognition<sup id=\"cite_ref-90\"><a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-90\">[90]</a></sup></li>\n",
    "\t<li>Protein Homology Detection<sup id=\"cite_ref-91\"><a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-91\">[91]</a></sup></li>\n",
    "\t<li>Predicting subcellular localization of proteins<sup id=\"cite_ref-92\"><a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-92\">[92]</a></sup></li>\n",
    "\t<li>Several prediction tasks in the area of business process management<sup id=\"cite_ref-93\"><a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-93\">[93]</a></sup></li>\n",
    "\t<li>Prediction in medical care pathways<sup id=\"cite_ref-94\"><a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#cite_note-94\">[94]</a></sup></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, pandas as pd; nltk.download('popular')\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contoh Kasus \n",
    "\n",
    "### Referensi: https://towardsdatascience.com/multi-class-text-classification-with-lstm-using-tensorflow-2-0-d88627c10a35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Data\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('data/bbc-text.csv')\n",
    "except:\n",
    "    !mkdir data\n",
    "    !wget -P data/ https://raw.githubusercontent.com/susanli2016/PyCon-Canada-2019-NLP-Tutorial/master/bbc-text.csv\n",
    "    df = pd.read_csv('data/bbc-text.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Preprocessing\n",
    "\n",
    "## Detail lebih lanjut di https://tau-data.id/nlptm-01/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_ = stopwords.words('english')\n",
    "print(stops_[:7])\n",
    "stops_ = set(stops_) # Best Practice with Stopwords adalah menggunakan STRUKTUR DATA \"set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "T = \"This is just a random statement of mine.\"\n",
    "token = TextBlob(T).words\n",
    "print(T)\n",
    "print(token)\n",
    "print(' '.join([t for t in token if t.lower() not in stops_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PreProcessing sederhana, bisa lebih baik lagi dengan menggunakan Lemma\n",
    "from tqdm import tqdm\n",
    "\n",
    "labels = df['category'].tolist()\n",
    "print(\"Contoh data sebelum preprocessing: \\n\", df['text'][0][:100])\n",
    "articles = []\n",
    "for i, d in tqdm(df.iterrows()):\n",
    "    articles.append(' '.join([t for t in TextBlob(d.text.lower()).words if t not in stops_]))\n",
    "\n",
    "print(\"Contoh data setelah preprocessing: \\n\", articles[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "embedding_dim = 64\n",
    "max_length = 200\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'\n",
    "training_portion = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Split ... sebaiknya CV dan gunakan fungsi pisah train-test (misal sklearn)\n",
    "train_size = int(len(articles) * training_portion)\n",
    "\n",
    "train_articles = articles[0: train_size]\n",
    "train_labels = labels[0: train_size]\n",
    "validation_articles = articles[train_size:]\n",
    "validation_labels = labels[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siapkan Struktur Data Training Data\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_articles)\n",
    "word_index = tokenizer.word_index\n",
    "train_sequences = tokenizer.texts_to_sequences(train_articles)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "# Siapkan Struktur Data Test Data\n",
    "validation_sequences = tokenizer.texts_to_sequences(validation_articles)\n",
    "validation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "# Siapkan Struktur data untuk Labels (perhatikan pada contoh ini label adalah string)\n",
    "label_tokenizer = Tokenizer()\n",
    "label_tokenizer.fit_on_texts(labels)\n",
    "training_label_seq = np.array(label_tokenizer.texts_to_sequences(train_labels))\n",
    "validation_label_seq = np.array(label_tokenizer.texts_to_sequences(validation_labels))\n",
    "\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
    "    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "print(model.summary())\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "history = model.fit(train_padded, training_label_seq, epochs=num_epochs, validation_data=(validation_padded, validation_label_seq), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()\n",
    "\n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediksi ke data baru\n",
    "\n",
    "## Karena menghasilkan probabilitas setiap kategory, softMax dapat digunakan untuk Soft Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = [\"A WeWork shareholder has taken the company to court over the near-$1.7bn (Â£1.3bn) leaving package approved for ousted co-founder Adam Neumann.\"]\n",
    "seq = tokenizer.texts_to_sequences(txt)\n",
    "padded = pad_sequences(seq, maxlen=max_length)\n",
    "pred = model.predict(padded)\n",
    "labels = ['sport', 'bussiness', 'politics', 'tech', 'entertainment']\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latihan 1:\n",
    "\n",
    "* Bandingkan dengan Tanpa LSTM seperti di module sebelumnya.\n",
    "* Lakukan seperti diatas pada data ini (perhatikan jumlah kategori menjadi 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "try:\n",
    "    f = open('data/20newsgroups_bin.pckl', 'rb') # Menghindari downloading data berkali-kali\n",
    "    Y, D = pickle.load(f); f.close()\n",
    "except:\n",
    "    categories = ['talk.politics.misc',  'rec.autos', 'sci.med', 'sci.space']\n",
    "    data = fetch_20newsgroups(subset='train', categories=categories,remove=('headers', 'footers', 'quotes'))\n",
    "    Y = data.target\n",
    "    D = [doc for doc in data.data]\n",
    "    f = open('data/20newsgroups_bin.pckl', 'wb') # save ke lokal drive\n",
    "    pickle.dump((Y, D), f); f.close()\n",
    "    \n",
    "'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jawaban disini\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latihan 2:\n",
    "\n",
    "* Lakukan Sentiment Analisis Bahasa Indonesia pada data berikut:\n",
    "\n",
    "\n",
    "# Sumber Data & Hasil Sebelumnya\n",
    "\n",
    "* Sumber Data: https://www.researchgate.net/publication/338409000_Dataset_Indonesia_untuk_Analisis_Sentimen\n",
    "* Dataset di GitHub: https://github.com/ridife/dataset-idsa\n",
    "\n",
    "## Mengambil Data Media Sosial Sendiri? https://tau-data.id/sma-01/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/ind_SA.csv\n",
    "\n",
    "dataSA = pd.read_csv('data/ind_SA.csv') # run locally\n",
    "dataSA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Juga biasa digunakan untuk deteksi anomali/outlier pada data bergantung waktu\n",
    "\n",
    "### https://www.renom.jp/notebooks/tutorial/time_series/lstm-anomalydetection/notebook.html\n",
    "\n",
    "<img alt=\"\" src=\"images/lstm_anomali_detection.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>End of Module Implementasi Deep Learning 02</h1>\n",
    "\n",
    "<hr />\n",
    "<img alt=\"\" src=\"images/meme_DL.jpg\"/>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
