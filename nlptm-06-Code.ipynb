{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2><strong><font color=\"blue\">Natural Language Processing dan Text Mining (NLPTM)</font></strong></h2></center>\n",
    "<center><h2><strong><font color=\"blue\">Social Media Analytics (SMA)</font></strong></h2></center>\n",
    "\n",
    "<center><h3><strong><font color=\"blue\"><a href=\"https://taudata.blogspot.com\">https://taudata.blogspot.com</a></font></strong></h3></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/covers/taudata-cover.jpg\"/>\n",
    "\n",
    "<center><h2><strong><font color=\"blue\">NLPTM-06: Pendahuluan Sentimen Analysis</font></strong></h2></center>\n",
    "<center><h3><strong><font color=\"blue\"><a href=\"https://taudata.blogspot.com/2022/05/nlptm-06.html\">https://taudata.blogspot.com/2022/05/nlptm-06.html</a></font></strong></h3></center>\n",
    "<b><center><h3>(C) Taufik Sutanto ~ taudata Analytics</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color=\"blue\">Outline :</font>\n",
    "\n",
    "* Corpus-Based Sentiment Analysis\n",
    "* Metode Supervised untuk Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:29:06.064890Z",
     "start_time": "2022-05-29T11:29:02.972225Z"
    }
   },
   "outputs": [],
   "source": [
    "# Jalankan Cell ini \"HANYA\" jika anda menggunakan Google Colab\n",
    "# Jika di jalankan di komputer local, silahkan lihat NLPTM-02 untuk instalasinya.\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import nltk\n",
    "\n",
    "try:\n",
    "    import google.colab; IN_COLAB = True\n",
    "    !wget https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/taudataNlpTm.py\n",
    "    !mkdir data\n",
    "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/slang.txt\n",
    "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/stopwords_id.txt\n",
    "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/stopwords_en.txt\n",
    "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/kata_dasar.txt\n",
    "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/wn-ind-def.tab\n",
    "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/wn-msa-all.tab\n",
    "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/ind_SA.csv\n",
    "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/all_indo_man_tag_corpus_model.crf.tagger\n",
    "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/dataset_tweet_sentiment_opini_film.csv\n",
    "    !pip install spacy unidecode textblob sastrawi pyLDAvis\n",
    "    !pip install --upgrade python-crfsuite gensim\n",
    "    !pip install sklearn-pycrfsuite\n",
    "    !python -m spacy download xx_ent_wiki_sm\n",
    "    !python -m spacy download xx_sent_ud_sm\n",
    "    !python -m spacy download en_core_web_sm\n",
    "\n",
    "    nltk.download('popular')\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running the code locally, please make sure all the python module versions agree with colab environment and all data/assets downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgement:\n",
    "* Sentimen Data Source: https://raw.githubusercontent.com/rizalespe/Dataset-Sentimen-Analisis-Bahasa-Indonesia/master/dataset_tweet_sentiment_opini_film.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:29:06.095893Z",
     "start_time": "2022-05-29T11:29:06.066891Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mulai dengan loading data\n",
    "import nltk, pickle\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "try:\n",
    "    f = open('data/20newsgroups.pckl', 'rb')\n",
    "    data = pickle.load(f)\n",
    "    f.close()\n",
    "except:\n",
    "    categories = ['sci.med', 'talk.politics.misc',  'rec.autos']\n",
    "    data = fetch_20newsgroups(categories=categories,remove=('headers', 'footers', 'quotes'))\n",
    "    f = open('data/20newsgroups.pckl', 'wb')\n",
    "    pickle.dump(data, f)\n",
    "    f.close()\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:29:06.112002Z",
     "start_time": "2022-05-29T11:29:06.096892Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merubah data ke bentuk yang biasa kita gunakan\n",
    "D = [doc for doc in data.data]\n",
    "Y = data.target\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:29:06.128119Z",
     "start_time": "2022-05-29T11:29:06.114002Z"
    }
   },
   "outputs": [],
   "source": [
    "set(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:29:06.143244Z",
     "start_time": "2022-05-29T11:29:06.129123Z"
    }
   },
   "outputs": [],
   "source": [
    "D[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:57:52.431041Z",
     "start_time": "2022-05-29T11:29:06.144247Z"
    }
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "import taudataNlpTm as tau \n",
    "from tqdm import tqdm\n",
    "\n",
    "stops, lemmatizer = tau.LoadStopWords(lang='en')\n",
    "\n",
    "for i,d in tqdm(enumerate(D)):\n",
    "    D[i] = tau.cleanText(d, lemma=None, stops=stops, symbols_remove = True, min_charLen=2)\n",
    "    # Change to lemma=lemmatizer when possible, it is set to None to make it faster\n",
    "print(D[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:57:52.446657Z",
     "start_time": "2022-05-29T11:57:52.431041Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bentuk VSM-nya\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase=True, stop_words='english',smooth_idf= True, sublinear_tf=True, \n",
    "                                   ngram_range=(1, 2), max_df=0.90, min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:57:52.635082Z",
     "start_time": "2022-05-29T11:57:52.446657Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed = 99\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(D, Y, test_size=0.3, random_state=seed)\n",
    "x_train = tfidf_vectorizer.fit_transform(x_train) # \"Fit_Transform\"\n",
    "x_test = tfidf_vectorizer.transform(x_test) # Perhatikan disini hanya \"Transform\"\n",
    "\n",
    "print(x_train.shape, x_test.shape) # Jumlah kolom Sama ==> ini penting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:57:52.650709Z",
     "start_time": "2022-05-29T11:57:52.635082Z"
    }
   },
   "outputs": [],
   "source": [
    "# Jangan lupa langkah penting ini! ... \n",
    "# Kenapa ada yang kosong?... coba fikirkan ... \n",
    "def hapusKosong(X,Y):\n",
    "    Y = Y[X.getnnz(1)>0] # delete label dokumen yang memiliki row =0 di tfidf-nya\n",
    "    X = X[X.getnnz(1)>0] # Remove Zero Rows\n",
    "    return X, Y\n",
    "\n",
    "x_train, y_train = hapusKosong(x_train, y_train)\n",
    "x_test, y_test = hapusKosong(x_test, y_test)\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:57:52.666336Z",
     "start_time": "2022-05-29T11:57:52.650709Z"
    }
   },
   "outputs": [],
   "source": [
    "# Kita gunakan metric yang umum\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:57:52.964601Z",
     "start_time": "2022-05-29T11:57:52.666336Z"
    }
   },
   "outputs": [],
   "source": [
    "# Naive Bayes: http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "nbc = gnb.fit(x_train.toarray(), y_train) # Kelemahan Implementasinya disini\n",
    "\n",
    "y_nbc = nbc.predict(x_test.toarray())\n",
    "accuracy_score(y_test, y_nbc)\n",
    "# Hati-hati Sparse ==> Dense bisa memenuhi memory untuk data relatif cukup besar\n",
    "# Akurasi cukup baik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:57:53.090457Z",
     "start_time": "2022-05-29T11:57:52.964601Z"
    }
   },
   "outputs": [],
   "source": [
    "# Decision Tree: http://scikit-learn.org/stable/modules/tree.html\n",
    "from sklearn import tree\n",
    "\n",
    "DT = tree.DecisionTreeClassifier()\n",
    "DT = DT.fit(x_train, y_train)\n",
    "\n",
    "y_DT = DT.predict(x_test)\n",
    "accuracy_score(y_test, y_DT)\n",
    "# Akurasi relatif rendah ==> Mengapa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:57:53.608675Z",
     "start_time": "2022-05-29T11:57:53.090457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mari coba perbaiki dengan Random Forest\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RandomForest = RandomForestClassifier()\n",
    "RandomForest.fit(x_train, y_train)\n",
    "\n",
    "y_RF = RandomForest.predict(x_test)\n",
    "accuracy_score(y_test, y_RF)\n",
    "# Sedikit membaik (expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:57:54.142089Z",
     "start_time": "2022-05-29T11:57:53.608675Z"
    }
   },
   "outputs": [],
   "source": [
    "# SVM: http://scikit-learn.org/stable/modules/svm.html\n",
    "from sklearn import svm\n",
    "\n",
    "dSVM = svm.SVC(decision_function_shape='ovo') # oneversus one SVM\n",
    "dSVM.fit(x_train, y_train)\n",
    "\n",
    "y_SVM = dSVM.predict(x_test)\n",
    "accuracy_score(y_test, y_SVM)\n",
    "# Mengapa akurasinya rendah? Mengejutkan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:57:58.625617Z",
     "start_time": "2022-05-29T11:57:54.142089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Neural Network: http://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "NN = MLPClassifier(hidden_layer_sizes=(30, 40))\n",
    "NN.fit(x_train, y_train)\n",
    "\n",
    "y_NN = NN.predict(x_test)\n",
    "accuracy_score(y_test, y_NN)\n",
    "# Cukup Baik, coba rubah jumlah layer dan Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunggu dulu ... yang kita lakukan belum cukup valid/objektif ... Mengapa?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:58:01.718093Z",
     "start_time": "2022-05-29T11:57:58.625617Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "# perhatikan sekarang kita menggunakan seluruh data\n",
    "# Bisa juga CV di training data ==> train, Test, Val splittting system\n",
    "X = tfidf_vectorizer.fit_transform(D) # \"Fit_Transform\"\n",
    "\n",
    "svm_ = svm.SVC(kernel='linear', decision_function_shape='ovo')\n",
    "mulai = time.time()\n",
    "scores_svm = cross_val_score(svm_, X, Y, cv=10, n_jobs=-2) \n",
    "waktu = time.time() - mulai\n",
    "# Interval Akurasi 95 CI \n",
    "print(\"Accuracy SVM: %0.2f (+/- %0.2f), Waktu = %0.3f detik\" % (scores_svm.mean(), scores_svm.std() * 2, waktu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:58:58.293394Z",
     "start_time": "2022-05-29T11:58:01.718093Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bandingkan dengan Neural Network\n",
    "nn_ = MLPClassifier(hidden_layer_sizes=(30, 40))\n",
    "mulai = time.time()\n",
    "scores_nn = cross_val_score(nn_, X, Y, cv=10, n_jobs=-2) \n",
    "waktu = time.time() - mulai\n",
    "# Interval Akurasi 95 CI \n",
    "print(\"Accuracy ANN: %0.2f (+/- %0.2f), Waktu = %0.3f detik\" % (scores_nn.mean(), scores_nn.std() * 2, waktu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:04.659623Z",
     "start_time": "2022-05-29T11:58:58.293394Z"
    }
   },
   "outputs": [],
   "source": [
    "# Kita bisa juga mengeluarkan metric evaluasi lainnya\n",
    "scores = cross_val_score(svm_, X, Y, cv=10, scoring='f1_macro')\n",
    "print(\"F1-Score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "# scoring pilih dari sini: http://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:05.083329Z",
     "start_time": "2022-05-29T11:59:04.659623Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt; plt.style.use('classic')\n",
    "import numpy as np, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:05.177519Z",
     "start_time": "2022-05-29T11:59:05.083329Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'SVM':scores_svm,'ANN':scores_nn})\n",
    "sns.boxplot(data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:05.318599Z",
     "start_time": "2022-05-29T11:59:05.177519Z"
    }
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "# Lexicon Based berdasarkan \n",
    "# pattern = https://www.clips.uantwerpen.be/pages/pattern-en#sentiment\n",
    "Sentence = \"I hate Bakpia\"\n",
    "testimonial = TextBlob(Sentence)\n",
    "print(testimonial.sentiment)\n",
    "print('Polarity=Sentimen =', testimonial.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Sentiment menghasilkan Tuple berpasangan (<strong>Polaritas</strong>, <strong>Subjectivitas</strong>).&nbsp;</p>\n",
    "\n",
    "<p>Polaritas memiliki nilai [-1, 1] ==&gt; negative~positive Sentimen</p>\n",
    "\n",
    "<p>Subjectivity memiliki nilai antara 0 sampai 1, dimana 0 paling objective dan 1 paling subjective.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagaimana Dengan Bahasa Indonesia?\n",
    "<p>[A simple trick]</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:26.607506Z",
     "start_time": "2022-05-29T11:59:05.318599Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    kalimat = 'Saya suka Bakpia'\n",
    "    K = TextBlob(kalimat).translate(to='en')\n",
    "    print(type(K), K)\n",
    "except:\n",
    "    K = False\n",
    "    print(\"Fungsi ini deprecated di TextBlob. Anda bisa gunakan https://translate.google.com secara manual\\\n",
    "          atau secara automatis dengan menggunakan API-nya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:26.623371Z",
     "start_time": "2022-05-29T11:59:26.607506Z"
    }
   },
   "outputs": [],
   "source": [
    "if not K:\n",
    "    K = TextBlob(\"Bakpia is so delicious\")\n",
    "print(K.sentiment)\n",
    "print('Polarity=Sentimen =', K.sentiment.polarity)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:26.639651Z",
     "start_time": "2022-05-29T11:59:26.624390Z"
    }
   },
   "outputs": [],
   "source": [
    "def SenSubModMood_ID(kalimat):\n",
    "    K = TextBlob(kalimat).translate(to='en')\n",
    "    pol,sub = K.sentiment\n",
    "    if pol>0:\n",
    "        pol='positive'\n",
    "    elif pol<0:\n",
    "        pol='negative'\n",
    "    else:\n",
    "        pol = 'netral'\n",
    "    if sub>0.5:\n",
    "        sub = 'Subjektif'\n",
    "    else:\n",
    "        sub = \"Objektif\"\n",
    "    return pol, sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:47.879815Z",
     "start_time": "2022-05-29T11:59:26.639651Z"
    }
   },
   "outputs": [],
   "source": [
    "kalimat = 'makan bakpia pakai kecap enak'\n",
    "try:\n",
    "    SenSubModMood_ID(kalimat)\n",
    "except:\n",
    "    print(\"Fungsi ini deprecated di TextBlob. Anda bisa gunakan https://translate.google.com secara manual\\\n",
    "          atau secara automatis dengan menggunakan API-nya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:56.136502Z",
     "start_time": "2022-05-29T11:59:47.879815Z"
    }
   },
   "outputs": [],
   "source": [
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "# Warning, mungkin lambat karena membentuk model classifier* terlebih dahulu.\n",
    "# *Berdasarkan NLTK corpus ==> Language dependent\n",
    "Sentence = \"Textblob is amazingly simple to use\"\n",
    "blob = TextBlob(Sentence, analyzer=NaiveBayesAnalyzer())\n",
    "blob.sentiment\n",
    "# Good Explanation: https://medium.com/nlpython/sentiment-analysis-analysis-ee5da4448e37\n",
    "# Output probabilitas prediksinya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagaimana dengan Sentiment Analysis menggunakan NBC untuk Bahasa indonesia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:56.152562Z",
     "start_time": "2022-05-29T11:59:56.136502Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    " \n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "def bentukClassifier(wPos, wNeg): # ,Nt\n",
    "    positive_features = [(word_feats(pos), 'pos') for pos in wPos]\n",
    "    negative_features = [(word_feats(neg), 'neg') for neg in wNeg]\n",
    "    #neutral_features = [(word_feats(neu), 'neu') for neu in Nt]\n",
    "    train_set = negative_features + positive_features# + neutral_features\n",
    "    return NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "def prediksiSentiment(kalimat, wPos, wNeg, negasi):\n",
    "    pos, neg = 0.0, 0.0\n",
    "    posWords, negWords = [], []\n",
    "    K = tau.cleanText(kalimat)\n",
    "    for w in wPos:\n",
    "        if w in K:\n",
    "            for ww in negasi:\n",
    "                kebalikan = False\n",
    "                inverted = ww+' '+w\n",
    "                if inverted in K:\n",
    "                    negWords.append(inverted)\n",
    "                    kebalikan = True\n",
    "                    break\n",
    "            if not kebalikan:\n",
    "                posWords.append(w)\n",
    "    for w in wNeg:\n",
    "        if w in K:\n",
    "            for ww in negasi:\n",
    "                kebalikan = False\n",
    "                inverted = ww+' '+w\n",
    "                if inverted in K:\n",
    "                    posWords.append(inverted)\n",
    "                    kebalikan = True\n",
    "                    break\n",
    "            if not kebalikan:\n",
    "                negWords.append(w)\n",
    "    \n",
    "    nPos, nNeg = len(posWords), len(negWords)\n",
    "    sum_ = nPos + nNeg\n",
    "    if sum_ == 0 or nPos==nNeg:\n",
    "        return 'netral', 0.0\n",
    "    else:\n",
    "        nPos, nNeg = nPos/sum_, nNeg/sum_\n",
    "        if nPos>nNeg and nPos>0.01:\n",
    "            return 'positif', nPos\n",
    "        elif nNeg>nPos and nNeg<-0.01:\n",
    "            return 'negatif', nNeg\n",
    "        else:\n",
    "            return 'netral', (nPos + nNeg)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:56.168220Z",
     "start_time": "2022-05-29T11:59:56.152562Z"
    }
   },
   "outputs": [],
   "source": [
    "wPos = ('keren', 'suka', 'cinta', 'bagus', 'mantap', 'sadis', 'top', 'enak', 'sedap')\n",
    "wNeg = ('jelek', 'benci','buruk', 'najis')\n",
    "wordS = (wPos, wNeg)\n",
    "negasi = ['ga', 'tidak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:56.184084Z",
     "start_time": "2022-05-29T11:59:56.168220Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence = \"makan pempek minumnya teh panas, biasa aja :)\"\n",
    "prediksiSentiment(sentence, wPos, wNeg, negasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:56.199687Z",
     "start_time": "2022-05-29T11:59:56.184084Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence = \"makan gorengan sambil minum kopi, enak tenan\"\n",
    "prediksiSentiment(sentence, wPos, wNeg, negasi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagaimana jika mau melakukannya dengan model klasifikasi (supervised learning) lain seperti modul sebelumnya?\n",
    "(e.g. SVM, NN, DT, k-NN, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:56.215283Z",
     "start_time": "2022-05-29T11:59:56.199687Z"
    }
   },
   "outputs": [],
   "source": [
    "# text Classification : independent variable\n",
    "d1 = 'Minum kopi pagi-pagi sambil makan pisang goreng is the best'\n",
    "d2 = 'Belajar NLP dan Text Mining ternyata seru banget'\n",
    "d3 = 'Palembang agak mendung hari ini'\n",
    "d4 =  'Sudah lumayan lama tukang Bakso belum lewat'\n",
    "d5 = 'Aduh ga banget makan Mie Ayam pakai kecap, please deh'\n",
    "d6 = 'Benci banget kalau melihat orang buang sampah sembarangan di jalan'\n",
    "d7 = 'Kalau liat orang ga taat aturan rasanya ingin ngegampar aja'\n",
    "d8 = 'Nikmatnya meniti jalan jalan penuh romansa di tengah kota bernuansa pendidikan'\n",
    "d9 = 'kemajuan bangsa ini ada pada kegigihan masyarakat dalam belajar dan bekerja'\n",
    "D = [d1,d2,d3,d4,d5,d6,d7,d8,d9]\n",
    "'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:56.231063Z",
     "start_time": "2022-05-29T11:59:56.215283Z"
    }
   },
   "outputs": [],
   "source": [
    "# dependent variable, misal 0=positif, 1=netral, 2=negatif\n",
    "Class = [0,0,1,1,2,2,2,1,0]\n",
    "dic = {0:'positif', 1:'netral', 2:'negatif'}\n",
    "print([dic[c] for c in Class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:56.247081Z",
     "start_time": "2022-05-29T11:59:56.231063Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bentuk VSM-nya seperti kemarin (skip preprocessing)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "vsm = vectorizer.fit_transform(D)\n",
    "vsm = vsm[vsm.getnnz(1)>0][:,vsm.getnnz(0)>0] # Remove zero rows and columns\n",
    "print(vsm.shape)\n",
    "str(vectorizer.vocabulary_)[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:56.262722Z",
     "start_time": "2022-05-29T11:59:56.247081Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lakukan klasifikasi (misal dengan SVM)\n",
    "dSVM = svm.SVC(kernel='linear')\n",
    "sen = dSVM.fit(vsm, Class).predict(vsm)\n",
    "print(accuracy_score(Class, sen))\n",
    "# Memakai seluruh training data karena sampel yang sangat kecil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:56.293970Z",
     "start_time": "2022-05-29T11:59:56.262722Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import nltk, warnings; warnings.simplefilter('ignore')\n",
    "import pandas as pd, taudataNlpTm as tau\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load DataFile CSV\n",
    "dataSA = pd.read_csv('data/ind_SA.csv') # run locally\n",
    "dataSA.head(), dataSA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T11:59:56.309589Z",
     "start_time": "2022-05-29T11:59:56.293970Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "dataSA['tweet_cleaned'] = ''\n",
    "dataSA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PreProcessing\n",
    "\n",
    "### Detail lebih lanjut di \n",
    "\n",
    "* https://taudata.blogspot.com/2020/04/nlptm-01.html\n",
    "* https://taudata.blogspot.com/2020/04/nlptm-02.html\n",
    "* https://taudata.blogspot.com/2022/04/nlptm-03.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T12:13:26.235239Z",
     "start_time": "2022-05-29T11:59:56.309589Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "stopId, lemmaId = tau.LoadStopWords(lang='id') \n",
    "for i, d in tqdm(dataSA.iterrows()):\n",
    "    doc = tau.cleanText(d.Tweet, lemma=lemmaId, stops = None, symbols_remove = True, min_charLen = 2, fixTag= True)\n",
    "    dataSA.at[i, \"tweet_cleaned\"] = doc\n",
    "    \n",
    "dataSA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T12:13:26.251242Z",
     "start_time": "2022-05-29T12:13:26.236239Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 99 # Biasakan menggunakan ini\n",
    "testSize = 0.2\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataSA[\"tweet_cleaned\"], dataSA[\"sentimen\"], \n",
    "                                                    test_size=testSize, random_state = seed)\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T12:13:26.506259Z",
     "start_time": "2022-05-29T12:13:26.253243Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vsm = TfidfVectorizer(lowercase=True, smooth_idf= True, sublinear_tf=True, \n",
    "                                   ngram_range=(1, 2), max_df=0.90, min_df=2)\n",
    "\n",
    "x_train = vsm.fit_transform(x_train) # \"Fit_Transform\"\n",
    "x_test = vsm.transform(x_test) # Perhatikan disini hanya \"Transform\"\n",
    "\n",
    "print(x_train.shape, x_test.shape) # Jumlah kolom Sama ==> ini penting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Document Classification ~ Sentiment Analysis\n",
    "\n",
    "* https://taudata.blogspot.com/2020/04/slcm-01.html\n",
    "* https://taudata.blogspot.com/2020/04/slcm-02.html\n",
    "* https://taudata.blogspot.com/2022/04/slcm-03.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T12:13:26.935278Z",
     "start_time": "2022-05-29T12:13:26.507259Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "model = neighbors.KNeighborsClassifier()\n",
    "kNN = model.fit(x_train, y_train)\n",
    "y_kNN = kNN.predict(x_test)\n",
    "\n",
    "print('Akurasi = ', accuracy_score(y_test, y_kNN))\n",
    "print(confusion_matrix(y_test, y_kNN))\n",
    "print(classification_report(y_test, y_kNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T12:13:38.135756Z",
     "start_time": "2022-05-29T12:13:26.936278Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "dSVM = svm.SVC()\n",
    "dSVM.fit(x_train, y_train)\n",
    "y_SVM = dSVM.predict(x_test)\n",
    "print('Akurasi = ', accuracy_score(y_test, y_SVM))\n",
    "print(confusion_matrix(y_test, y_SVM))\n",
    "print(classification_report(y_test, y_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T12:17:56.599292Z",
     "start_time": "2022-05-29T12:13:38.137757Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "NN = MLPClassifier()\n",
    "NN.fit(x_train, y_train)\n",
    "y_NN = NN.predict(x_test)\n",
    "\n",
    "print('Akurasi = ', accuracy_score(y_test, y_NN))\n",
    "print(confusion_matrix(y_test, y_NN))\n",
    "print(classification_report(y_test, y_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T12:17:56.615292Z",
     "start_time": "2022-05-29T12:17:56.600294Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T12:19:26.326664Z",
     "start_time": "2022-05-29T12:17:56.617295Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Optimal parameter k-NN dengan GRIDSEARCH\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataSA[\"tweet_cleaned\"], dataSA[\"sentimen\"], \n",
    "                                                    test_size=testSize, random_state = seed)\n",
    "# Perhatikan kita pakai data awal : Text karena kita akan optimalkan preprocessing juga\n",
    "\n",
    "kCV = 5\n",
    "metric = 'accuracy'\n",
    "params = {}\n",
    "params['tfidfvectorizer__min_df'] = [5, 10, 15]\n",
    "params['tfidfvectorizer__max_df'] = [0.5, 0.75, 0.95]\n",
    "params['tfidfvectorizer__smooth_idf'] = [True] # [True, False]\n",
    "params['tfidfvectorizer__sublinear_tf'] = [True] # [True, False]\n",
    "params['tfidfvectorizer__ngram_range'] = [(1, 1), (1, 2), (1,3)]\n",
    "params['kneighborsclassifier__n_neighbors'] = [3, 5, 10]\n",
    "params['kneighborsclassifier__weights'] = ('distance', 'uniform')\n",
    "\n",
    "pipe = make_pipeline(TfidfVectorizer(), neighbors.KNeighborsClassifier())\n",
    "gridCV = GridSearchCV(pipe, params, cv=kCV, scoring=metric, verbose=1, n_jobs=-1) # , pre_dispatch='2*n_jobs', pre_dispatch min 2* n_jobs\n",
    "gridCV.fit(x_train, y_train)\n",
    "print(gridCV.best_score_)\n",
    "print(gridCV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T12:19:26.342663Z",
     "start_time": "2022-05-29T12:19:26.328664Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Optimal parameter SVM dengan RandomSEARCH\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "pipeSVM = make_pipeline(TfidfVectorizer(), svm.SVC())\n",
    "print(sorted(pipeSVM.get_params().keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T12:22:24.139231Z",
     "start_time": "2022-05-29T12:19:26.344666Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Optimal parameter SVM dengan RandomizedSearch\n",
    "\n",
    "paramsSVM = {}\n",
    "paramsSVM['tfidfvectorizer__min_df'] = [5, 10, 30]\n",
    "paramsSVM['tfidfvectorizer__max_df'] = [0.5, 0.75, 0.95]\n",
    "paramsSVM['tfidfvectorizer__smooth_idf'] = [True] # [True, False]\n",
    "paramsSVM['tfidfvectorizer__sublinear_tf'] = [True] # [True, False]\n",
    "paramsSVM['tfidfvectorizer__ngram_range'] = [(1, 1), (1, 2), (1,3)]\n",
    "paramsSVM['svc__C'] = [0.1, 10, 100] #sp.stats.uniform(scale=1)\n",
    "paramsSVM['svc__gamma'] = [1.0, 0.1, 0.001]\n",
    "paramsSVM['svc__kernel'] = ['rbf', 'poly', 'sigmoid', 'linear']\n",
    "paramsSVM['svc__decision_function_shape'] = ['ovo', 'ovr']\n",
    "\n",
    "randsvmCV = RandomizedSearchCV(pipeSVM, paramsSVM, cv=kCV, scoring=metric, verbose=1, n_iter=30, random_state=seed, n_jobs=-1) # , pre_dispatch='2*n_jobs' pre_dispatch min 2* n_jobs\n",
    "randsvmCV.fit(x_train, y_train)\n",
    "print(randsvmCV.best_score_)\n",
    "print(randsvmCV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T12:22:24.155230Z",
     "start_time": "2022-05-29T12:22:24.140244Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Optimal parameter ANN dengan RandomSEARCH\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "\n",
    "pipeNN = make_pipeline(TfidfVectorizer(), MLPClassifier())\n",
    "print(sorted(pipeNN.get_params().keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T12:27:50.152063Z",
     "start_time": "2022-05-29T12:22:24.156231Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "paramsNN = {}\n",
    "paramsNN['tfidfvectorizer__min_df'] = [5, 10, 30]\n",
    "paramsNN['tfidfvectorizer__max_df'] = [0.5, 0.75, 0.95]\n",
    "paramsNN['tfidfvectorizer__smooth_idf'] = [True] # [True, False]\n",
    "paramsNN['tfidfvectorizer__sublinear_tf'] = [True] # [True, False]\n",
    "paramsNN['tfidfvectorizer__ngram_range'] = [(1, 1), (1, 2), (1,3)]\n",
    "paramsNN['mlpclassifier__hidden_layer_sizes'] = [(5,10), (20,30), (30,50)] \n",
    "paramsNN['mlpclassifier__learning_rate'] = ['constant', 'invscaling', 'adaptive']\n",
    "paramsNN['mlpclassifier__activation'] = ['logistic', 'tanh', 'relu' ]\n",
    "\n",
    "randNnCV = RandomizedSearchCV(pipeNN, paramsNN, cv=kCV, scoring=metric, verbose=1, n_iter=30, random_state=seed, n_jobs=-1) # , pre_dispatch='2*n_jobs' pre_dispatch min 2* n_jobs\n",
    "randNnCV.fit(x_train, y_train)\n",
    "print(randNnCV.best_score_)\n",
    "print(randNnCV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T12:27:50.168063Z",
     "start_time": "2022-05-29T12:27:50.153065Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "knn_score = gridCV.cv_results_['mean_test_score'][:10]\n",
    "svm_score = randsvmCV.cv_results_['mean_test_score'][:10]\n",
    "ann_score = randNnCV.cv_results_['mean_test_score'][:10]\n",
    "ann_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T12:27:50.248064Z",
     "start_time": "2022-05-29T12:27:50.169063Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "\n",
    "models = ['kNN', 'SVM', 'NN']\n",
    "scores = [knn_score, svm_score, ann_score]\n",
    "\n",
    "data = {m:s for m,s in zip(models, scores)}\n",
    "for name in data.keys():\n",
    "    print(\"Accuracy %s: %0.2f (+/- %0.2f)\" % (name, data[name].mean(), data[name].std() * 2))\n",
    "\n",
    "sns.boxplot(data=pd.DataFrame(data), orient='h')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## “meta-algorithms” : Bagging & Boosting\n",
    "* Ensemble https://www.youtube.com/watch?v=Un9zObFjBH0 \n",
    "* Bagging https://www.youtube.com/watch?v=2Mg8QD0F1dQ \n",
    "* Boosting https://www.youtube.com/watch?v=GM3CDQfQ4sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T12:28:02.285538Z",
     "start_time": "2022-05-29T12:27:50.249064Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Contoh Voting (Bagging) di Python\n",
    "# Kita menggunakan semua parameter optimal dari langkah sebelumnya\n",
    "from sklearn.ensemble import AdaBoostClassifier, VotingClassifier\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataSA[\"tweet_cleaned\"], dataSA[\"sentimen\"], \n",
    "                                                    test_size=testSize, random_state = seed)\n",
    "                                                    \n",
    "vsm = TfidfVectorizer(lowercase=True, smooth_idf= True, sublinear_tf=True, \n",
    "                                   ngram_range=(1, 1), max_df=0.95, min_df=10)\n",
    "\n",
    "x_train = vsm.fit_transform(x_train) # \"Fit_Transform\"\n",
    "x_test = vsm.transform(x_test) # Perhatikan disini hanya \"Transform\"\n",
    "\n",
    "kNN = neighbors.KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
    "SVM = svm.SVC(C=0.1, gamma=1, kernel='rbf', decision_function_shape='ovr')\n",
    "ann = MLPClassifier(hidden_layer_sizes=(5, 10), learning_rate='invscaling', activation='logistic')\n",
    "\n",
    "ensemble = VotingClassifier(estimators=[('k-NN', kNN), ('SVM', SVM), ('ANN', ann)], voting='hard')\n",
    "ensemble.fit(x_train, y_train)\n",
    "y_ens = ensemble.score(x_test, y_test)\n",
    "\n",
    "print('Akurasi k-NN = ', gridCV.best_score_)\n",
    "print('Akurasi SVM = ', randsvmCV.best_score_)\n",
    "print('Akurasi ANN = ', randNnCV.best_score_)\n",
    "print('Akurasi Ensemble = ', y_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T12:28:39.201967Z",
     "start_time": "2022-05-29T12:28:02.286538Z"
    }
   },
   "outputs": [],
   "source": [
    "kNN = neighbors.KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
    "SVM = svm.SVC(C=0.1, gamma=1, kernel='rbf', decision_function_shape='ovr', probability=True)\n",
    "ann = MLPClassifier(hidden_layer_sizes=(5, 10), learning_rate='invscaling', activation='logistic')\n",
    "\n",
    "ensemble = VotingClassifier(estimators=[('k-NN', kNN), ('SVM', SVM), ('ANN', ann)], voting='soft')\n",
    "ensemble.fit(x_train, y_train)\n",
    "y_ens = ensemble.score(x_test, y_test)\n",
    "\n",
    "print('Akurasi k-NN = ', gridCV.best_score_)\n",
    "print('Akurasi SVM = ', randsvmCV.best_score_)\n",
    "print('Akurasi ANN = ', randNnCV.best_score_)\n",
    "print('Akurasi Ensemble = ', y_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T12:28:45.615320Z",
     "start_time": "2022-05-29T12:28:39.202967Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "class_names = [\"Negatif\", \"Netral\", \"Positif\"]\n",
    "disp = plot_confusion_matrix(ensemble, x_train, y_train, display_labels=class_names, cmap=plt.cm.Blues, ax=ax)# , normalize='true'\n",
    "disp.ax_.set_title(\"Confusion Matrix - Training\")\n",
    "print(disp.confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T12:28:47.179320Z",
     "start_time": "2022-05-29T12:28:45.617320Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compared to training error to make sure overfitting not happening\n",
    "ensemble_pred = ensemble.predict(x_test)\n",
    "print(classification_report(y_test, ensemble_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Module\n",
    "\n",
    "<hr />\n",
    "<p><img alt=\"\" src=\"images/meme-cartoon/6_ML_Class.jpg\" style=\"height:495px; width:640px\" /></p>\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
